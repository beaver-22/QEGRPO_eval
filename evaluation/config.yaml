# src/evaluation/config.yaml

# ===================================================================
# Models to evaluate on the MSMARCO retrieval task.
# Add any new model here (GRPO, SFT, baseline etc...).
# ===================================================================

retrieval_model:
  name: e5-large
  path: intfloat/multilingual-e5-large-instruct
  wrapper: SentenceTransformer
  device: 

expansion_models:
  #1) baseline
  - name: base
    path: Qwen/Qwen3-1.7B
    wrapper: AutoModelForCausalLM
    device: cuda:1

  # 2) Supervised Fineâ€‘Tuning model
  - name: sft
    path: Chaew00n/test-supervised-fine-tuning
    wrapper: AutoModelForCausalLM
    device: cuda:0

  # 3) QEGRPO model
  - name: grpo
    path: Chaew00n/test-policy-optimization
    wrapper: AutoModelForCausalLM
    device: cuda:0

# ===================================================================
# Evaluation settings
# ===================================================================
evaluation:
  datasets: [MSMARCO]
  output_root: ./results/msmarco
  batch_size: 64

# ===================================================================
# Logging options (optional)
# ===================================================================
logging:
  wandb: false
  tensorboard: ./tb_logs
  csv: ./results/csv

# src/evaluation/config.yaml

