# src/evaluation/config.yaml

# ===================================================================
# Models to evaluate on the MSMARCO retrieval task.
# Add any new model here (GRPO, SFT, baseline etc...).
# ===================================================================

retrieval_model:
  name: e5-base
  path: intfloat/e5-base-v2
  encoder: Transformers
  pool_type: "avg"
  query_prompt: "Query: "
  doc_prompt: "Passage: "
  device: cuda

expansion_models:
  # 1) QEGRPO Expansion model
  - name: grpo
    path: Chaew00n/test-policy-optimization-query-expansion-0522
    adapted: True
    device: cuda:0

  # 2) QEGRPO Rewrite model
  - name: grpo
    path: Chaew00n/test-policy-optimization-query-rewrite-0522
    adapted: True
    device: cuda:0
    QR: True

  # 3) baseline - Untrained
  - name: base
    path: "Qwen/Qwen3-1.7B"
    adapted: False
    device: cuda:0

  # 4) Supervised Fineâ€‘Tuning model
  - name: sft
    path: Chaew00n/test-supervised-fine-tuning
    adapted: True
    device: cuda:0

  # 5) baseline
  - name: peusdo
    path: False
    adapted: False
    device: cuda:0


# ===================================================================
# Evaluation settings
# ===================================================================
evaluation:
  datasets: [MSMARCO]
  output_root: ./results/msmarco
  batch_size: 128

# ===================================================================
# Logging options (optional)
# ===================================================================
logging:
  wandb: false
  tensorboard: ./tb_logs
  csv: ./results/csv

# src/evaluation/config.yaml

