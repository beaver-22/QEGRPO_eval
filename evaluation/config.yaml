# src/evaluation/config.yaml

# ===================================================================
# Models to evaluate on the MSMARCO retrieval task.
# Add any new model here (GRPO, SFT, baseline etc...).
# ===================================================================

retrieval_model:
  name: e5-large
  path: intfloat/e5-large-v2
  wrapper: SentenceTransformer
  device: cuda:1

expansion_models:
  # 0) baseline
  - name: base
    path: None
    adapted: False
    device: cuda:1

  # 1) QEGRPO model
  #- name: grpo
  #  path: Chaew00n/test-policy-optimization
  #  adapted: True
  #  device: cuda:0

  # 2) Supervised Fineâ€‘Tuning model
  #- name: sft
  #  path: Chaew00n/test-supervised-fine-tuning
  #  adapted: True
  #  device: cuda:0

  # 3) baseline
  #- name: base
  #  path: "Qwen/Qwen3-1.7B"
  #  adapted: False
  #  device: cuda:1


# ===================================================================
# Evaluation settings
# ===================================================================
evaluation:
  datasets: [MSMARCO]
  output_root: ./results/msmarco
  batch_size: 64

# ===================================================================
# Logging options (optional)
# ===================================================================
logging:
  wandb: false
  tensorboard: ./tb_logs
  csv: ./results/csv

# src/evaluation/config.yaml

